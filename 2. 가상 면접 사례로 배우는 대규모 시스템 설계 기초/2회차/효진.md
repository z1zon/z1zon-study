### 처리율 제한 장치 (`rate limiter`)
- 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치
- HTTP에서 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한함. API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출은 처리가 중단됨.
  ex)
-   사용자는 초당 2회 이상 새 글을 올릴 수 없다.
-   같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
-   같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

- API에 처리율 제한 장치를 두면 좋은 점
    - DoS(`Denial of Service`) 공격에 의한 자원 고갈(`Resource Starvation`)을 방지할 수 있다.
    -   비용을 절감할 수 있다. 처리를 제한해 서버를 많이 두지 않고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있다. 특히 요청 당 비용이 드는 Third party API를 사용하고 있는 경우, 횟수 제한을 통해 과도한 비용을 막을 수 있다.
    - 서버 과부하를 막는다. 봇, 크롤러 등에서 오는 잘못된 이용 패턴으로 유발된 트래픽을 제한한다.

### 처리율 제한 장치는 어디에 둘 것인가?
-   클라이언트?
    -   별로 좋지 않다. 위변조 가능, 모든 클라이언트 구현 어려움, ...
-   서버
    -   서버에 붙여두는 것
-   미들웨어
    -   요청이 서버에 들어가기 이전 미들웨어에서 먼저 통제
    -   제한된 요청이라고 판단되면 서버에 안보내고, 미들웨어 단에서 [HTTP 429 (Too many requests)](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429) 반환
    -   Cloud MSA 구조에서 보통 API Gateway를 활용 → Rate limiter, SSL termination, User Authentication, IP Whitelist 등 지원

서버/미들웨어 어디에 둘 것인가는 정답 없음

-   하지만 어디에 둘 것인가를 결정할 때 고려해야할 점은 있음
    - 프로그래밍 언어, 캐시 서비스 등 기술 스택 점검 → 현재 서버 측 언어를 통해 구현이 가능한가? 충분한가?
    - 현재 비즈니스에 맞는 처리율 제한 알고리즘 찾기 → 미들웨어 및 제 3자가 서비스하는 Gateway를 사용한다면 적절한 알고리즘이 있는지 확인
    - MSA 구조를 사용하고 있어 이미 API Gateway 사용하고 있다면, 기존 API Gateway에 Rate limiter 포함시키는 것 고려

### 처리율 제한 알고리즘
-   토큰 버킷 (Token bucket)
-   누출 버킷 (Leaky bucket)
-   고정 윈도 카운터 (Fixed window counter)
-   이동 윈도 로그 (Sliding window log)
-   이동 윈도 카운터 (Sliding window counter)

### 카운터는 어디에 저장할 것인가?
메모리상에서 동작하는 캐시가 바람직할 것

-   빠르고, 시간에 기반한 만료 정책을 지원.
-   Redis → `INCR`, `EXPIRE` 명령어 지원
    -   `INCR`: 메모리에 저장된 카운터 1증가
    -   `EXPIRE`: 카운터에 저장한 타임아웃 값 설정 → 만료되면 자동으로 삭제

### 처리율 제한 규칙

#### (1) 처리율 한도 초과 트래픽 처리
-   `HTTP 429 응답 (Too many requests): 어떤 요청이 한도 제한에 걸릴때 응답
-   경우에 따라서 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관할 수 있다.

#### (2) 처리율 제한 장치가 사용하는 HTTP 헤더

-   클라이언트가 자기 요청이 처리율 제한에 걸리고 있는지에 대한 정보를 아래 HTTP 헤더를 통해 전달한다.
-   `X-Ratelimit-Remaining`: 윈도 내에 남은 처리 가능 요청의 수
-   `X-Ratelimit-Limit`: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
-   `X-Ratelimit-Retry-After`: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림

### 분산 환경에서의 처리율 제한 장치의 구현

#### (1) 경쟁 조건 (race condition)

**경쟁 이슈가 발생하는 동작**

-   레디스에서 카운터의 값을 읽는다.
-   counter +1 의 값이 임계치를 넘는지 본다.
-   넘지 않는다면 레디스에 보관된 카운터 값을 1만큼 증가시킨다.

**경쟁 이슈 해결**
- 경쟁 조건 문제를 해결할 수 있는 가장 쉬운 방법은 Lock이지만, 성능 이슈가 커진다. 이를 해결할 수 있는 다른 방안은 루아 스크립트와 정렬집합 레디스 자료구조이다.
- [https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/](https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/)
- [https://goalgorithm.wordpress.com/2019/06/08/designing-an-api-rate-limiter/](https://goalgorithm.wordpress.com/2019/06/08/designing-an-api-rate-limiter/)

#### (2) 동기화 (synchronization)

**이슈**
-   여러대의 처리율 제한 장치를 사용할 경우 요창이 분산될 수 있다.

**해결 방법**
-   Redis 같은 중앙 집중형 데이터 저장소를 사용해서 해결
-   Sticky session 을 사용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 할 수 있다.


#### (3) 성능 최적화
- 지연시간을 줄이기 위해 사용자의 트래픽을 가장 가까운 Edge 서버로 전달하여 지연시간을 줄인다.