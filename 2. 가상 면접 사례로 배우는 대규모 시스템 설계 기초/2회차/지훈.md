# 처리율 제한 장치의 설계

처리율 제한 장치는 클라이언트 또는 서버가 보내는 트래픽의 처리율을 제어하기 위한 장치다.
미리 정해놓은 threshold를 넘어서면 이후 요청들을 block하는 역할을 헌다.

해당 장치는 클라이언트 혹은 서버에서 구현할 수 있는데 서버에서 구현하는게 바람직하다. (클라이언트 측 요청은 쉽게 변조가 가능)

처리율 제한이 필요한 이유는 Dos(Denial of Service) 공격을 막기 위함과 특정 기능에 대해 요청 수를 제한하기 위해 필요하다.

- 사용자는 초당 2회 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드(reward)를 요청할 수 없다.

### 구현 방법

처리율 제한 장치를 구현할 수 있는 방법에는 여러가지가 있다.

- API 서버에 직접 두는 방법
- 미들웨어로 만들어 API 서버에 요청이 가기전 미들웨어에서 처리
- API Gateway를 활용

### 처리율 제한 알고리즘

- 토큰 버킷 알고리즘(token bucket)
- 누출 버킷 알고리즘(leaky bucket)
- 고정 윈도 카운터(fixed window counter)
- 이동 윈도 로그(sliding window log)
- 이동 윈도 카운터(sliding window counter)

> 토큰 버킷 알고리즘

처리율 제한에 폭넓게 이용되고 있는 알고리즘이다. 사전에 정의된 버킷의 크기와 토큰 공급률을 기준으로 동작한다. 버킷은 API 엔드포인트 별로 다르고 사전에 정의된 버킷 크기와 공급률도 다르다.

- 동작방식

  - 사전에 지정된 용량을 갖는 토큰 버킷 컨테이너가 존재
  - 요청을 처리할 때마다 하나의 토큰이 사용 (사전에 정의된 시간을 주기로 토큰이 채워짐)
  - 요청이 도착하면 버킷에 토큰이 남아있는지 검사
    - 토큰이 남아있다면? --> 요청을 처리
    - 토큰이 없다면? --> 요청을 거부

- 장점

  - 구현이 쉬움
  - 메모리 사용 측면에서도 효율적
  - 짧은 시간에 집중되는 트래픽도 처리 가능 (버킷에 남은 토큰이 있기만 하면 요청은 시스템에 전달)

- 단점
  - 버킷 크기와 토큰 공급률을 사전에 정의해야하는데, 이 값을 트래픽에 맞게 적절하게 튜닝하는 것이 까다로움

> 누출 버킷 알고리즘

요청 처리율이 고정되어 있는 버킷을 가지고 처리한다. 먼저 들어온 요청을 먼저 처리하는 FIFO(Fisrt-In-First-Out) 형태로 구현한다. 요청을 담을 버킷의 크기와 지정된 시간마다 몇 개의 요청을 처리할지에 대한 처리율을 사전에 정의한다.

- 동작방식

  - 요청이 도착하면 큐를 검사
    - 큐가 가득 찼다면? --> 요청을 거부
    - 큐가 비어있다면? --> 큐에 요청을 추가
  - 지정된 시간마다 큐에서 요청을 꺼내서 처리

- 장점

  - 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
  - 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 곳에 적합 (이거 때문에 별로지 않나..?)

- 단점
  - 단시간에 트래픽이 몰리는 경우 큐에 오래된 요청들이 쌓이게 되고, 이로 인해 최신 요청들이 거부됨
  - 사전에 정의해야하는 두 개의 인자를 튜닝하기 까다로움

> 고정 윈도 카운터 알고리즘

정해진 타임라인에 처리할 요청의 임계치를 두는 방식이다.

- 동작방식
  - 타임라인을 고정된 간격의 윈도(window)로 나누고, 각 윈도마다 카운터를 붙임
  - 요청이 들어올 때마다 카운터 값이 1씩 증가
  - 카운터 값이 사전에 정의한 임계치에 도달하면 새로운 윈도가 생길때까지 새로운 요청은 거부

**해당 알고리즘에 가장 큰 문제는 윈도 경계 부근에 요청이 몰릴 경우 미리 정의한 임계치보다 더 많은 요청을 처리할 수 있다는 점이다.**

- 장점

  - 메모리 효율이 좋음
  - 이해하기 쉬움
  - 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 적합함

- 단점
  - 윈도 경게 부근에 트래픽이 몰릴 경우, 기대했던 처리 한도보다 더 많은 양의 요청을 처리하게 됨

## ETC

### API Gateway는 어디에 위치해야할까?

- LB 앞 단? API Gateway <-> LB <-> Application
  - 이 경우 API Gateway가 모든 트래픽을 다 받아서 LB의 의미가 없지 않나?
- LB 와 Application 사이? LB <-> API Gateway <-> Application
  - API Gateway가 로드밸런싱 역할도 할 수 있음

**처리율 제한 장치로 많이 쓰이는 API Gateway는 로드 밸런싱과 처리율 제한 두 가지 기능을 모두 제공**

### race condition에 사용되는 redis의 sorted set 자료구조
