# 문제 이해 및 설계 범위

- 비디오 업로드 및 재생 기능
  - 매일 새로 요구되는 저장 용량 = 5백만 X 10% X 300MB = 150TB
- 재생 품질 선택 가능
- 낮은 인프라 비용
  - CDN 비용
- 높은 가용성과 규모 확장성과 안정성

# 개략적 설계안

## 비디오 업로드

### 컴포넌트

- `LB`: API 서버 각각으로 요청을 고르게 분산
- `API Server`: 비디오 스트리밍을 제외한 다른 모든 요청을 처리하는 서버
- `Metadata DB/Cache`: 비디오의 메타데이터를 보관 및 캐싱
- `BLOB (Binary Large Object Storage)`: 원본 비디오를 보관할 대형 이진 파일 저장소
- `Transcoding Server`: 비디오의 포맷을 변환(=인코딩)하는 절차로 단말이나 대역폭 요구사항에 맞는 최적의 비디오 스트림 제공을 위해 필요
- `Transcoding Storage`: 비디오 인코딩이 완료된 비디오를 저장하는 BLOB 저장소
- `CDN`: 비디오를 캐싱하고 비디오 스트리밍을 담당
- `Completion Queue`: 비디오 인코딩 완료 이벤트를 보관할 메시지 큐
- `Completion Handler`: `Completion Queue`에서 이벤트 데이터를 꺼내 `Metadata DB/Cache`를 갱신할 작업 서버들

### 프로세스

1. 비디오를 원본 저장소에 업로드
2. `Transcoding Server`가 원본 저장소에서 비디오를 가져와 인코딩이 시작
3. 아래 두 절차가 병렬로 실행됨
   1. 인코딩이 완료된 비디오를 `Transcoding Storage`에 저장함
   2. `Completion Queue`에 인코딩 완료 이벤트를 넣은 후에 비디오를 CDN에 올리고 `Completion Handler`가 이벤트 데이터를 큐에서 꺼내 `Metadata DB/Cache`를 갱신함

## 비디오 스트리밍

- 사용자 단말에서 가장 가까운 CDN Edge Server가 비디오 스트리밍 전송을 담당하여 전송 지연은 아주 낮음

# 상세설계

## 비디오 트랜스코딩

### 필요성

- 비디오의 용량은 줄이고 다양한 비디오 포맷을 지원하기 위함

### 개념

- 컨테이너: 비디오 파일, 오디오, 메타데이터를 담는 바구니 (ex. .avi, .mov, .mp3)
- 코덱: 비디오 화질을 보존하면서 파일 크기를 줄일 목적으로 고안된 압축 및 압축 해제 알고리즘
- DAG (Directed Acyclic Graph) 모델
  - 작업을 단계별로 배열하여 해당 작업들을 순차적 혹은 병렬적으로 실행될 수 있도록 하기 위해 도입한 알고리즘
  - 비디오 인코딩을 위한 여러 절차들을 병렬적으로 수행하기 위해 적용하기 좋음

## Video Encoding Architecture

### Preprocessor

> initial component in video encoding pipeline

- `Validation`: 업로드된 비디오가 명시된 형식(format, size, etc)에 맞는지 검증

- `Splitting`: 비디오 스트림을 GOP(Group of Pictures) 단위로 쪼개어 병렬 처리가 가능하도록 함

- `Metadata Extraction`: 비디오에서 resolution, duration, codec 정보와 같은 metadata를 뽑아냄

### DAG Scheduler

> orchestrates the encoding tasks by managing dependencies and execution order

- `Task Scheduling`: 비디오 인코딩 과정을 작은 작업 단위로 쪼개어 스케줄링함

- 비디오 추출(0) -> 비디오 인코딩(1) | 썸네일(1)

- 오디오 추출(0) -> 오디오 인코딩(1)

- 메타데이터 추출(0)

- `Dependency Management`: 각 작업들은 dependencies를 충족할 수 있는 순서로 실행됨 (0 -> 1)

- `Load Balancing`: 작업들을 자원 활용성과 효율성을 최적화할 수 있는 방향으로 분배함

- `Fault Tolerance`: 실패한 작업들에 대해서는 retry strategy를 마련함

### Resource Manager

> handles the allocation and management of computational resources required for encoding tasks

- `Resource Allocation`: 작업 요구사항에 맞게 CPU, GPU, 메모리 등의 자원들을 할당하는 역할을 함

- `Monitoring`: 지속적으로 자원 활용량과 퍼포먼스 메트릭스를 모니터링함

- `Scaling`: 필요에 따라 서버 자원 scaling-up or down을 적저리 해줌

- `Job Queueing`: 인코딩 작업들을 우선순위 큐(PQ)에 쌓아둠

- Task Queue: 실행할 작업들이 담겨있는 PQ

- Worker Queue: 서버 가용 정보들이 담겨있는 PQ

- Running Queue: 현재 작업 중인 작업 및 서버 정보가 담겨있는 PQ

### Resource Worker

> actual computational units for performing encoding tasks assigned by the DAG schedular with resources allocated by the resource manager

- `Parallel Processing`: 여러 비디오 청크들의 인코딩 작업을 병렬적으로 수행함

- `Status Reporting`: task completion status, progress, errors와 같은 정보들을 DAG schedular에게 보고함

### Temporary Storage

> intermediate storage solution to hold data during encoding process

- `Staging Area`: 비디오 청크들, 중간 연산 결과들을 보관해둠

- `Consistency`: 이어진 인코딩 절차에서 항상 up-to-date 정보를 일관되게 쓸 수 있도록 도움을 줌

- `Performance`: high-speed read and write access

- `Cleanup`: 인코딩 절차가 끝나면 관련한 데이터들을 cleanup하여 불필요한 저장공간을 차지하지 않도록 함

## DAG 자료구조

> 각 작업들을 노드로 표현하고 directed edge는 노드 간의 의존관계를 표현한다

```python

from collections import defaultdict, deque



class DAG:

    def __init__(self):

        self.graph = defaultdict(list) # Adjacency list representation

        self.in_degree = defaultdict(int) # Keeps track of in-degrees for topological sorting



    def add_edge(self, u, v):

        self.graph[u].append(v)

        self.in_degree[v] += 1

        if u not in self.in_degree:

        self.in_degree[u] = 0


    def topological_sort(self):

        queue = deque([node for node in self.in_degree if self.in_degree[node] == 0])

        sorted_list = []

        while queue:

        u = queue.popleft()

        sorted_list.append(u)

        for v in self.graph[u]:

        self.in_degree[v] -= 1

        if self.in_degree[v] == 0:

        queue.append(v)



        if len(sorted_list) != len(self.in_degree):

        raise Exception("The graph has at least one cycle.")

        return sorted_list

    def execute_tasks(self):

        sorted_tasks = self.topological_sort()

        for task in sorted_tasks:

            self.run_task(task)

    def run_task(self, task):
        # 구현 예정



# Example usage:

dag = DAG()

dag.add_edge('A', 'B')

dag.add_edge('A', 'C')

dag.add_edge('B', 'D')

dag.add_edge('C', 'D')


dag.execute_tasks()
```

- topology_sort를 활용해 dependencies를 고려해 작업 순서를 정렬함

- 비디오 추출 작업이 비디오 인코딩 및 썸네일 작업보다 선행되어야 함

- 만약 topology_sort를 했을 때 sorted_list와 in_degree 길이가 동일하지 않다면 작업 간의 cycle이 있다는 것을 의미함 (if sorted_list is less than in_degree size)

## Resource Worker가 작업을 실행하는 부분 구현

```python

import concurrent.futures

from collections import defaultdict, deque

import threading

import time



#... 중략



def execute_tasks(self):

	sorted_tasks = self.topological_sort()

	with concurrent.futures.ThreadPoolExecutor() as executor:

		futures = {}

	for task in sorted_tasks:

		futures[task] = executor.submit(self.run_task_with_dependencies, task)

	for future in concurrent.futures.as_completed(futures.values()):

		future.result() # Re-raise any exceptions that occurred



def run_task_with_dependencies(self, task):

	# Wait for all dependencies to be completed

	while not self.dependencies_completed(task):

		time.sleep(0.1)
	# Simulate task execution
	print(f"Running task {task}")

	time.sleep(1) # Simulate time taken to complete the task

	print(f"Completed task {task}")

	# Mark the task as completed
	with self.lock:
		self.completed_tasks.add(task)



def dependencies_completed(self, task):
	with self.lock:
		return all(dep in self.completed_tasks for dep in self.task_dependencies[task])



# Example usage:

dag = DAG()

dag.add_edge('A', 'B')

dag.add_edge('A', 'C')

dag.add_edge('B', 'D')

dag.add_edge('C', 'D')

# Uncomment the following line to introduce a cycle and test cycle detection

# dag.add_edge('D', 'A')

dag.execute_tasks()

```

- Track Dependencies: 각 작업을 수행하기 전 선행되어야 하는 작업 리스트를 관리

- Check Dependencies Before Execution: 작업을 실행하기 전 선행 작업들이 모두 완료되었는지 확인 후 모두 완료되었을 경우에만 작업 시작

- Thread Pooling: 쓰레들을 활용해 병렬적인 작업 수행 가능

- Locking Mechanism: completed_task를 업데이트할 때는 thread-safe를 위해 lock을 걸어두고 업데이트함

## Golang으로 다시 구현해본다면?

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

type DAG struct {
	graph          map[string][]string
	inDegree       map[string]int
	taskDependencies map[string]map[string]struct{}
	completedTasks map[string]struct{}
	mu             sync.Mutex
}

func NewDAG() *DAG {
	return &DAG{
		graph:          make(map[string][]string),
		inDegree:       make(map[string]int),
		taskDependencies: make(map[string]map[string]struct{}),
		completedTasks: make(map[string]struct{}),
	}
}

func (dag *DAG) AddEdge(u, v string) {
	dag.graph[u] = append(dag.graph[u], v)
	dag.inDegree[v]++
	if _, exists := dag.inDegree[u]; !exists {
		dag.inDegree[u] = 0
	}
	if _, exists := dag.taskDependencies[v]; !exists {
		dag.taskDependencies[v] = make(map[string]struct{})
	}
	dag.taskDependencies[v][u] = struct{}{}
}

func (dag *DAG) TopologicalSort() ([]string, error) {
	queue := make([]string, 0)
	sortedList := make([]string, 0)

	for node, degree := range dag.inDegree {
		if degree == 0 {
			queue = append(queue, node)
		}
	}

	for len(queue) > 0 {
		u := queue[0]
		queue = queue[1:]
		sortedList = append(sortedList, u)
		for _, v := range dag.graph[u] {
			dag.inDegree[v]--
			if dag.inDegree[v] == 0 {
				queue = append(queue, v)
			}
		}
	}

	if len(sortedList) != len(dag.inDegree) {
		return nil, fmt.Errorf("the graph has at least one cycle")
	}

	return sortedList, nil
}

func (dag *DAG) ExecuteTasks() error {
	sortedTasks, err := dag.TopologicalSort()
	if err != nil {
		return err
	}

	var wg sync.WaitGroup
	for _, task := range sortedTasks {
		wg.Add(1)
		go func(task string) {
			defer wg.Done()
			dag.runTaskWithDependencies(task)
		}(task)
	}
	wg.Wait()

	return nil
}

func (dag *DAG) runTaskWithDependencies(task string) {
	// Wait for all dependencies to be completed
	for !dag.dependenciesCompleted(task) {
		time.Sleep(100 * time.Millisecond)
	}

	// Simulate task execution
	fmt.Printf("Running task %s\n", task)
	time.Sleep(1 * time.Second) // Simulate time taken to complete the task
	fmt.Printf("Completed task %s\n", task)

	// Mark the task as completed
	dag.mu.Lock()
	dag.completedTasks[task] = struct{}{}
	dag.mu.Unlock()
}

func (dag *DAG) dependenciesCompleted(task string) bool {
	dag.mu.Lock()
	defer dag.mu.Unlock()

	for dep := range dag.taskDependencies[task] {
		if _, completed := dag.completedTasks[dep]; !completed {
			return false
		}
	}
	return true
}

func main() {
	dag := NewDAG()
	dag.AddEdge("A", "B")
	dag.AddEdge("A", "C")
	dag.AddEdge("B", "D")
	dag.AddEdge("C", "D")
	// Uncomment the following line to introduce a cycle and test cycle detection
	// dag.AddEdge("D", "A")

	if err := dag.ExecuteTasks(); err != nil {
		fmt.Println(err)
	}
}


```
