# 문제 이해 및 설계 범위

- 비디오 업로드 및 재생 기능
	- 매일 새로 요구되는 저장 용량 = 5백만 X 10% X 300MB = 150TB
- 재생 품질 선택 가능
- 낮은 인프라 비용
	- CDN 비용
- 높은 가용성과 규모 확장성과 안정성


# 개략적 설계안
## 비디오 업로드
### 컴포넌트
- `LB`: API 서버 각각으로 요청을 고르게 분산
- `API Server`: 비디오 스트리밍을 제외한 다른 모든 요청을 처리하는 서버
- `Metadata DB/Cache`: 비디오의 메타데이터를 보관 및 캐싱
- `BLOB (Binary Large Object Storage)`: 원본 비디오를 보관할 대형 이진 파일 저장소
- `Transcoding Server`: 비디오의 포맷을 변환(=인코딩)하는 절차로 단말이나 대역폭 요구사항에 맞는 최적의 비디오 스트림 제공을 위해 필요
- `Transcoding Storage`: 비디오 인코딩이 완료된 비디오를 저장하는 BLOB 저장소
- `CDN`: 비디오를 캐싱하고 비디오 스트리밍을 담당
- `Completion Queue`: 비디오 인코딩 완료 이벤트를 보관할 메시지 큐
- `Completion Handler`: `Completion Queue`에서 이벤트 데이터를 꺼내 `Metadata DB/Cache`를 갱신할 작업 서버들

### 프로세스
1. 비디오를 원본 저장소에 업로드
2. `Transcoding Server`가 원본 저장소에서 비디오를 가져와 인코딩이 시작
3. 아래 두 절차가 병렬로 실행됨
	1. 인코딩이 완료된 비디오를 `Transcoding Storage`에 저장함
	2. `Completion Queue`에 인코딩 완료 이벤트를 넣은 후에 비디오를 CDN에 올리고 `Completion Handler`가 이벤트 데이터를 큐에서 꺼내 `Metadata DB/Cache`를 갱신함

## 비디오 스트리밍

- 사용자 단말에서 가장 가까운 CDN Edge Server가 비디오 스트리밍 전송을 담당하여 전송 지연은 아주 낮음

# 상세설계

## 비디오 트랜스코딩
### 필요성
- 비디오의 용량은 줄이고 다양한 비디오 포맷을 지원하기 위함
### 개념
- 컨테이너: 비디오 파일, 오디오, 메타데이터를 담는 바구니 (ex. .avi, .mov, .mp3)
- 코덱: 비디오 화질을 보존하면서 파일 크기를 줄일 목적으로 고안된 압축 및 압축 해제 알고리즘
- DAG (Directed Acyclic Graph) 모델
	- 작업을 단계별로 배열하여 해당 작업들을 순차적 혹은 병렬적으로 실행될 수 있도록 하기 위해 도입한 알고리즘
	- 비디오 인코딩을 위한 여러 절차들을 병렬적으로 수행하기 위해 적용하기 좋음


  

## Video Encoding Architecture

### Preprocessor

> initial component in video encoding pipeline

  

- `Validation`: 업로드된 비디오가 명시된 형식(format, size, etc)에 맞는지 검증

- `Splitting`: 비디오 스트림을 GOP(Group of Pictures) 단위로 쪼개어 병렬 처리가 가능하도록 함

- `Metadata Extraction`: 비디오에서 resolution, duration, codec 정보와 같은 metadata를 뽑아냄

  

### DAG Scheduler

> orchestrates the encoding tasks by managing dependencies and execution order

  

- `Task Scheduling`: 비디오 인코딩 과정을 작은 작업 단위로 쪼개어 스케줄링함

- 비디오 추출(0) -> 비디오 인코딩(1) | 썸네일(1)

- 오디오 추출(0) -> 오디오 인코딩(1)

- 메타데이터 추출(0)

- `Dependency Management`: 각 작업들은 dependencies를 충족할 수 있는 순서로 실행됨 (0 -> 1)

- `Load Balancing`: 작업들을 자원 활용성과 효율성을 최적화할 수 있는 방향으로 분배함

- `Fault Tolerance`: 실패한 작업들에 대해서는 retry strategy를 마련함

  

### Resource Manager

> handles the allocation and management of computational resources required for encoding tasks

  

- `Resource Allocation`: 작업 요구사항에 맞게 CPU, GPU, 메모리 등의 자원들을 할당하는 역할을 함

- `Monitoring`: 지속적으로 자원 활용량과 퍼포먼스 메트릭스를 모니터링함

- `Scaling`: 필요에 따라 서버 자원 scaling-up or down을 적저리 해줌

- `Job Queueing`: 인코딩 작업들을 우선순위 큐(PQ)에 쌓아둠

- Task Queue: 실행할 작업들이 담겨있는 PQ

- Worker Queue: 서버 가용 정보들이 담겨있는 PQ

- Running Queue: 현재 작업 중인 작업 및 서버 정보가 담겨있는 PQ

  

### Resource Worker

> actual computational units for performing encoding tasks assigned by the DAG schedular with resources allocated by the resource manager

  

- `Parallel Processing`: 여러 비디오 청크들의 인코딩 작업을 병렬적으로 수행함

- `Status Reporting`: task completion status, progress, errors와 같은 정보들을 DAG schedular에게 보고함

### Temporary Storage

> intermediate storage solution to hold data during encoding process

  

- `Staging Area`: 비디오 청크들, 중간 연산 결과들을 보관해둠

- `Consistency`: 이어진 인코딩 절차에서 항상 up-to-date 정보를 일관되게 쓸 수 있도록 도움을 줌

- `Performance`: high-speed read and write access

- `Cleanup`: 인코딩 절차가 끝나면 관련한 데이터들을 cleanup하여 불필요한 저장공간을 차지하지 않도록 함

  
  

## DAG 자료구조

  

> 각 작업들을 노드로 표현하고 directed edge는 노드 간의 의존관계를 표현한다

  

```python

from collections import defaultdict, deque

  

class DAG:

	def __init__(self):
	
		self.graph = defaultdict(list) # Adjacency list representation
		
		self.in_degree = defaultdict(int) # Keeps track of in-degrees for topological sorting

  

	def add_edge(self, u, v):
	
		self.graph[u].append(v)
		
		self.in_degree[v] += 1
		
		if u not in self.in_degree:
		
		self.in_degree[u] = 0
  

	def topological_sort(self):
	
		queue = deque([node for node in self.in_degree if self.in_degree[node] == 0])
		
		sorted_list = []
	
		while queue:
		
		u = queue.popleft()
		
		sorted_list.append(u)
		
		for v in self.graph[u]:
		
		self.in_degree[v] -= 1
		
		if self.in_degree[v] == 0:
		
		queue.append(v)
		
		  
		
		if len(sorted_list) != len(self.in_degree):
		
		raise Exception("The graph has at least one cycle.")
		
		return sorted_list

  

def execute_tasks(self):

	sorted_tasks = self.topological_sort()
	
	for task in sorted_tasks:
	
		self.run_task(task)

  

def run_task(self, task):
	# 구현 예정

  

# Example usage:

dag = DAG()

dag.add_edge('A', 'B')

dag.add_edge('A', 'C')

dag.add_edge('B', 'D')

dag.add_edge('C', 'D')

  

dag.execute_tasks()

```

- topology_sort를 활용해 dependencies를 고려해 작업 순서를 정렬함

- 비디오 추출 작업이 비디오 인코딩 및 썸네일 작업보다 선행되어야 함

- 만약 topology_sort를 했을 때 sorted_list와 in_degree 길이가 동일하지 않다면 작업 간의 cycle이 있다는 것을 의미함 (if sorted_list is less than in_degree size)

  

## Resource Worker가 작업을 실행하는 부분 구현

```python

import concurrent.futures

from collections import defaultdict, deque

import threading

import time

  

#... 중략

  

def execute_tasks(self):

	sorted_tasks = self.topological_sort()
	
	with concurrent.futures.ThreadPoolExecutor() as executor:
	
		futures = {}
	
	for task in sorted_tasks:
	
		futures[task] = executor.submit(self.run_task_with_dependencies, task)
	
	for future in concurrent.futures.as_completed(futures.values()):
	
		future.result() # Re-raise any exceptions that occurred

  

def run_task_with_dependencies(self, task):

	# Wait for all dependencies to be completed
	
	while not self.dependencies_completed(task):
	
		time.sleep(0.1)
	# Simulate task execution
	print(f"Running task {task}")
	
	time.sleep(1) # Simulate time taken to complete the task
	
	print(f"Completed task {task}")

	# Mark the task as completed
	with self.lock:
		self.completed_tasks.add(task)

  

def dependencies_completed(self, task):
	with self.lock:
		return all(dep in self.completed_tasks for dep in self.task_dependencies[task])

  

# Example usage:

dag = DAG()

dag.add_edge('A', 'B')

dag.add_edge('A', 'C')

dag.add_edge('B', 'D')

dag.add_edge('C', 'D')

# Uncomment the following line to introduce a cycle and test cycle detection

# dag.add_edge('D', 'A')

dag.execute_tasks()

```

  

- Track Dependencies: 각 작업을 수행하기 전 선행되어야 하는 작업 리스트를 관리

- Check Dependencies Before Execution: 작업을 실행하기 전 선행 작업들이 모두 완료되었는지 확인 후 모두 완료되었을 경우에만 작업 시작

- Thread Pooling: 쓰레들을 활용해 병렬적인 작업 수행 가능

- Locking Mechanism: completed_task를 업데이트할 때는 thread-safe를 위해 lock을 걸어두고 업데이트함

  
  

## Golang으로 다시 구현해본다면?

```go
package main


import (

"fmt"

"sync"

"time"

)

  

type DAG struct {

graph map[string][]string

inDegree map[string]int

taskDependencies map[string]map[string]struct{}

completedTasks map[string]struct{}

mu sync.Mutex

}

  

func NewDAG() *DAG {

return &DAG{

graph: make(map[string][]string),

inDegree: make(map[string]int),

taskDependencies: make(map[string]map[string]struct{}),

completedTasks: make(map[string]struct{}),

}

}

  

func (dag *DAG) AddEdge(u, v string) {
    dag.graph[u] = append(dag.graph[u], v)

    dag.inDegree[v]++

    if _, exists := dag.inDegree[u]; !exists {

    dag.inDegree[u] = 0
}

if _, exists := dag.taskDependencies[v]; !exists {

    dag.taskDependencies[v] = make(map[string]struct{})

    }

    dag.taskDependencies[v][u] = struct{}{}
}

  

func (dag *DAG) TopologicalSort() ([]string, error) {
    queue := make([]string, 0)

    sortedList := make([]string, 0)

    

    for node, degree := range dag.inDegree {

    if degree == 0 {

    queue = append(queue, node)

    }
}

  

for len(queue) > 0 {

    u := queue[0]

    queue = queue[1:]

    sortedList = append(sortedList, u)

    for _, v := range dag.graph[u] {

    dag.inDegree[v]--

    if dag.inDegree[v] == 0 {

        queue = append(queue, v)

    }

}

}

  

if len(sortedList) != len(dag.inDegree) {

    return nil, fmt.Errorf("the graph has at least one cycle")

}

  

return sortedList, nil

}

  

func (dag *DAG) ExecuteTasks() error {

sortedTasks, err := dag.TopologicalSort()

if err != nil {

return err

}

  

var wg sync.WaitGroup

for _, task := range sortedTasks {

wg.Add(1)

go func(task string) {

defer wg.Done()

dag.runTaskWithDependencies(task)

}(task)

}

wg.Wait()

  

return nil

}

  

func (dag *DAG) runTaskWithDependencies(task string) {

// Wait for all dependencies to be completed

for !dag.dependenciesCompleted(task) {

time.Sleep(100 * time.Millisecond)

}

  

// Simulate task execution

fmt.Printf("Running task %s\n", task)

time.Sleep(1 * time.Second) // Simulate time taken to complete the task

fmt.Printf("Completed task %s\n", task)

  

// Mark the task as completed

dag.mu.Lock()

dag.completedTasks[task] = struct{}{}

dag.mu.Unlock()

}

  

func (dag *DAG) dependenciesCompleted(task string) bool {

dag.mu.Lock()

defer dag.mu.Unlock()

  

for dep := range dag.taskDependencies[task] {

if _, completed := dag.completedTasks[dep]; !completed {

return false

}

}

return true

}

  

func main() {

dag := NewDAG()

dag.AddEdge("A", "B")

dag.AddEdge("A", "C")

dag.AddEdge("B", "D")

dag.AddEdge("C", "D")

// Uncomment the following line to introduce a cycle and test cycle detection

// dag.AddEdge("D", "A")

  

if err := dag.ExecuteTasks(); err != nil {

fmt.Println(err)

}

}

```
